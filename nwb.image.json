{"datasets":[{"attributes":[{"doc":"base image (use GrayscaleImage, RGBImage, RGBAImage, etc.)","dtype":"text","name":"help"},{"doc":"pixels / cm","dtype":"float","name":"resolution","required":false},{"doc":"description of image","dtype":"text","name":"description","required":false}],"dims":["y","x"],"doc":"Grayscale image","neurodata_type_def":"GrayscaleImage","neurodata_type_inc":"Image","shape":[null,null]},{"attributes":[{"doc":"base image (use GrayscaleImage, RGBImage, RGBAImage, etc.)","dtype":"text","name":"help"},{"doc":"pixels / cm","dtype":"float","name":"resolution","required":false},{"doc":"description of image","dtype":"text","name":"description","required":false}],"dims":["y","x","R,G,B"],"doc":"Color image","neurodata_type_def":"RGBImage","neurodata_type_inc":"Image","shape":[null,null,3]},{"attributes":[{"doc":"base image (use GrayscaleImage, RGBImage, RGBAImage, etc.)","dtype":"text","name":"help"},{"doc":"pixels / cm","dtype":"float","name":"resolution","required":false},{"doc":"description of image","dtype":"text","name":"description","required":false}],"dims":["y","x","R,G,B,A"],"doc":"Color image with transparency","neurodata_type_def":"RGBAImage","neurodata_type_inc":"Image","shape":[null,null,4]}],"groups":[{"attributes":[{"doc":"Value is 'Storage object for time-series 2-D image data'","dtype":"text","name":"help","value":"Storage object for time-series 2-D image data"},{"default_value":"no comments","doc":"Human-readable comments about the TimeSeries. This second descriptive field can be used to store additional information, or descriptive information if the primary description field is populated with a computer-readable string.","dtype":"text","name":"comments","required":false},{"default_value":"no description","doc":"Description of TimeSeries","dtype":"text","name":"description","required":false}],"datasets":[{"attributes":[{"default_value":1,"doc":"Scalar to multiply each element in data to convert it to the specified unit","dtype":"float32","name":"conversion","required":false},{"default_value":0,"doc":"Smallest meaningful difference between values in data, stored in the specified by unit. COMMENT: E.g., the change in value of the least significant bit, or a larger number if signal noise is known to be present. If unknown, use -1.0","dtype":"float32","name":"resolution","required":false},{"doc":"The base unit of measure used to store data. This should be in the SI unit. COMMENT: This is the SI unit (when appropriate) of the stored data, such as Volts. If the actual data is stored in millivolts, the field 'conversion' below describes how to convert the data to the specified SI unit.","dtype":"text","name":"unit"}],"dims":[["frame","y","x"],["frame","z","y","x"]],"doc":"Either binary data containing image or empty.","dtype":"numeric","name":"data","quantity":"?","shape":[[null,null,null],[null,null,null,null]]},{"dims":["rank"],"doc":"Number of pixels on x, y, (and z) axes.","dtype":"int32","name":"dimension","quantity":"?","shape":[null]},{"attributes":[{"dims":["num_files"],"doc":"Each entry is the frame number (within the full ImageSeries) of the first frame in the corresponding external_file entry. This serves as an index to what frames each file contains, allowing random access.Zero-based indexing is used.  (The first element will always be zero).","dtype":"int","name":"starting_frame","shape":[null]}],"dims":["num_files"],"doc":"Path or URL to one or more external file(s). Field only present if format=external. NOTE: this is only relevant if the image is stored in the file system as one or more image file(s). This field should NOT be used if the image is stored in another HDF5 file and that file is HDF5 linked to this file.","dtype":"text","name":"external_file","quantity":"?","shape":[null]},{"doc":"Format of image. If this is 'external' then the field external_file contains the path or URL information to that file. For tiff, png, jpg, etc, the binary representation of the image is stored in data. If the format is raw then the fields bit_per_pixel and dimension are used. For raw images, only a single channel is stored (eg, red).","dtype":"text","name":"format","quantity":"?"}],"doc":"General image data that is common between acquisition and stimulus time series. Sometimes the image data is stored in the HDF5 file in a raw format while other times it will be stored as an external image file in the host file system. The data field will either be binary data or empty. TimeSeries::data array structure: [frame] [y][x] or [frame][z][y][x].","neurodata_type_def":"ImageSeries","neurodata_type_inc":"TimeSeries"},{"attributes":[{"doc":"Value is 'An alpha mask that is applied to a presented visual stimulus'","dtype":"text","name":"help","value":"An alpha mask that is applied to a presented visual stimulus"},{"default_value":"no comments","doc":"Human-readable comments about the TimeSeries. This second descriptive field can be used to store additional information, or descriptive information if the primary description field is populated with a computer-readable string.","dtype":"text","name":"comments","required":false},{"default_value":"no description","doc":"Description of TimeSeries","dtype":"text","name":"description","required":false}],"doc":"An alpha mask that is applied to a presented visual stimulus. The data[] array contains an array of mask values that are applied to the displayed image. Mask values are stored as RGBA. Mask can vary with time. The timestamps array indicates the starting time of a mask, and that mask pattern continues until it's explicitly changed.","links":[{"doc":"Link to ImageSeries that mask is applied to.","name":"masked_imageseries","target_type":"ImageSeries"}],"neurodata_type_def":"ImageMaskSeries","neurodata_type_inc":"ImageSeries"},{"attributes":[{"doc":"Value is 'Time-series image stack for optical recording or stimulus'","dtype":"text","name":"help","value":"Time-series image stack for optical recording or stimulus"},{"default_value":"no comments","doc":"Human-readable comments about the TimeSeries. This second descriptive field can be used to store additional information, or descriptive information if the primary description field is populated with a computer-readable string.","dtype":"text","name":"comments","required":false},{"default_value":"no description","doc":"Description of TimeSeries","dtype":"text","name":"description","required":false}],"datasets":[{"doc":"Distance from camera/monitor to target/eye.","dtype":"float32","name":"distance","quantity":"?"},{"dims":[["width|height"],["width|height|depth"]],"doc":"Width, height and depth of image, or imaged area (meters).","dtype":"float32","name":"field_of_view","quantity":"?","shape":[[2],[3]]},{"doc":"Description of image relative to some reference frame (e.g., which way is up). Must also specify frame of reference.","dtype":"text","name":"orientation","quantity":"?"}],"doc":"Image data that is presented or recorded. A stimulus template movie will be stored only as an image. When the image is presented as stimulus, additional data is required, such as field of view (eg, how much of the visual field the image covers, or how what is the area of the target being imaged). If the OpticalSeries represents acquired imaging data, orientation is also important.","neurodata_type_def":"OpticalSeries","neurodata_type_inc":"ImageSeries"},{"attributes":[{"doc":"Value is 'A sequence that is generated from an existing image stack. Frames can be presented in an arbitrary order. The data[] field stores frame number in reference stack'","dtype":"text","name":"help","value":"A sequence that is generated from an existing image stack. Frames can be presented in an arbitrary order. The data[] field stores frame number in reference stack"},{"default_value":"no comments","doc":"Human-readable comments about the TimeSeries. This second descriptive field can be used to store additional information, or descriptive information if the primary description field is populated with a computer-readable string.","dtype":"text","name":"comments","required":false},{"default_value":"no description","doc":"Description of TimeSeries","dtype":"text","name":"description","required":false}],"datasets":[{"attributes":[{"default_value":1,"doc":"Scalar to multiply each element in data to convert it to the specified unit","dtype":"float32","name":"conversion","required":false},{"default_value":0,"doc":"Smallest meaningful difference between values in data, stored in the specified by unit. COMMENT: E.g., the change in value of the least significant bit, or a larger number if signal noise is known to be present. If unknown, use -1.0","dtype":"float32","name":"resolution","required":false},{"doc":"The base unit of measure used to store data. This should be in the SI unit. COMMENT: This is the SI unit (when appropriate) of the stored data, such as Volts. If the actual data is stored in millivolts, the field 'conversion' below describes how to convert the data to the specified SI unit.","dtype":"text","name":"unit"}],"dims":["num_times"],"doc":"Index of the frame in the referenced ImageSeries.","dtype":"int","name":"data","shape":[null]}],"doc":"Stores indices to image frames stored in an ImageSeries. The purpose of the ImageIndexSeries is to allow a static image stack to be stored somewhere, and the images in the stack to be referenced out-of-order. This can be for the display of individual images, or of movie segments (as a movie is simply a series of images). The data field stores the index of the frame in the referenced ImageSeries, and the timestamps array indicates when that image was displayed.","links":[{"doc":"HDF5 link to TimeSeries containing images that are indexed.","name":"indexed_timeseries","target_type":"ImageSeries"}],"neurodata_type_def":"IndexSeries","neurodata_type_inc":"TimeSeries"}]}
