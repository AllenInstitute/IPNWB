{"datasets":[{"dims":["y","x"],"doc":"A grayscale image.","neurodata_type_def":"GrayscaleImage","neurodata_type_inc":"Image","shape":[null,null]},{"dims":["y","x","R, G, B"],"doc":"A color image.","neurodata_type_def":"RGBImage","neurodata_type_inc":"Image","shape":[null,null,3]},{"dims":["y","x","R, G, B, A"],"doc":"A color image with transparency.","neurodata_type_def":"RGBAImage","neurodata_type_inc":"Image","shape":[null,null,4]}],"groups":[{"datasets":[{"dims":[["frame","y","x"],["frame","z","y","x"]],"doc":"Binary data representing images across frames.","dtype":"numeric","name":"data","quantity":"?","shape":[[null,null,null],[null,null,null,null]]},{"dims":["rank"],"doc":"Number of pixels on x, y, (and z) axes.","dtype":"int32","name":"dimension","quantity":"?","shape":[null]},{"attributes":[{"dims":["num_files"],"doc":"Each external image may contain one or more consecutive frames of the full ImageSeries. This attribute serves as an index to indicate which frames each file contains, to faciliate random access. The 'starting_frame' attribute, hence, contains a list of frame numbers within the full ImageSeries of the first frame of each file listed in the parent 'external_file' dataset. Zero-based indexing is used (hence, the first element will always be zero). For example, if the 'external_file' dataset has three paths to files and the first file has 5 frames, the second file has 10 frames, and the third file has 20 frames, then this attribute will have values [0, 5, 15]. If there is a single external file that holds all of the frames of the ImageSeries (and so there is a single element in the 'external_file' dataset), then this attribute should have value [0].","dtype":"int","name":"starting_frame","shape":[null]}],"dims":["num_files"],"doc":"Paths to one or more external file(s). The field is only present if format='external'. This is only relevant if the image series is stored in the file system as one or more image file(s). This field should NOT be used if the image is stored in another NWB file and that file is linked to this file.","dtype":"text","name":"external_file","quantity":"?","shape":[null]},{"default_value":"raw","doc":"Format of image. If this is 'external', then the attribute 'external_file' contains the path information to the image files. If this is 'raw', then the raw (single-channel) binary data is stored in the 'data' dataset. If this attribute is not present, then the default format='raw' case is assumed.","dtype":"text","name":"format","quantity":"?"}],"doc":"General image data that is common between acquisition and stimulus time series. Sometimes the image data is stored in the file in a raw format while other times it will be stored as a series of external image files in the host file system. The data field will either be binary data, if the data is stored in the NWB file, or empty, if the data is stored in an external image stack. [frame][y][x] or [frame][z][y][x].","neurodata_type_def":"ImageSeries","neurodata_type_inc":"TimeSeries"},{"doc":"An alpha mask that is applied to a presented visual stimulus. The 'data' array contains an array of mask values that are applied to the displayed image. Mask values are stored as RGBA. Mask can vary with time. The timestamps array indicates the starting time of a mask, and that mask pattern continues until it's explicitly changed.","links":[{"doc":"Link to ImageSeries object that this image mask is applied to.","name":"masked_imageseries","target_type":"ImageSeries"}],"neurodata_type_def":"ImageMaskSeries","neurodata_type_inc":"ImageSeries"},{"datasets":[{"doc":"Distance from camera/monitor to target/eye.","dtype":"float32","name":"distance","quantity":"?"},{"dims":[["width, height"],["width, height, depth"]],"doc":"Width, height and depth of image, or imaged area, in meters.","dtype":"float32","name":"field_of_view","quantity":"?","shape":[[2],[3]]},{"doc":"Description of image relative to some reference frame (e.g., which way is up). Must also specify frame of reference.","dtype":"text","name":"orientation","quantity":"?"}],"doc":"Image data that is presented or recorded. A stimulus template movie will be stored only as an image. When the image is presented as stimulus, additional data is required, such as field of view (e.g., how much of the visual field the image covers, or how what is the area of the target being imaged). If the OpticalSeries represents acquired imaging data, orientation is also important.","neurodata_type_def":"OpticalSeries","neurodata_type_inc":"ImageSeries"},{"datasets":[{"dims":["num_times"],"doc":"Index of the frame in the referenced ImageSeries.","dtype":"int","name":"data","shape":[null]}],"doc":"Stores indices to image frames stored in an ImageSeries. The purpose of the ImageIndexSeries is to allow a static image stack to be stored somewhere, and the images in the stack to be referenced out-of-order. This can be for the display of individual images, or of movie segments (as a movie is simply a series of images). The data field stores the index of the frame in the referenced ImageSeries, and the timestamps array indicates when that image was displayed.","links":[{"doc":"Link to ImageSeries object containing images that are indexed.","name":"indexed_timeseries","target_type":"ImageSeries"}],"neurodata_type_def":"IndexSeries","neurodata_type_inc":"TimeSeries"}]}
